# Day 4 : Study Time AI

**Day 5: Study Time Gen AI**  
**Time Interval:** 00:00 - 37:25  
**Summary**  
- **üîç Overview**: The session begins with a recap of previous lessons covering **AI basics**, **machine learning**, and **linear regression**, aiming to conclude the linear regression topic while introducing **logistic regression**.
- **üìê Continuation of Linear Regression**: The discussion continues on **linear regression**, particularly focusing on the **calculation of loss** and introducing the concept of the **cost function**. The session emphasizes the relevance of **mean squared error** as a critical extension of the loss function for refining algorithms.
- **üß† Understanding Loss and Cost Functions**: It highlights the importance of understanding **loss** (the difference between expected and predicted values) and **cost functions** (which aid in minimizing errors and improving model accuracy).
- **üõ† Practical Calculation**: The instructor provides insights on calculating cost using squared differences, illustrating how these computations affect the overall accuracy of the model and stressing the necessity of understanding these calculations for model adjustments.
- **üéØ Optimization Process**: The session includes a discussion on the **optimization of models** by adjusting parameters (like W1 and W2) to minimize the cost function, detailing systematic techniques for achieving this reduction.
- **üßÆ Introduction to Gradient Descent**: A brief introduction to **gradient descent** is provided as a method for identifying optimal values for model parameters, focusing on reducing the cost function through incremental steps.
- **üöÄ Next Steps**: The video concludes with a promise to further explore **gradient descent** and its crucial role in optimizing machine learning models in the next session.

# Transcript 


0:2:36 -  hey hi everyone um so today um in continuation to what we have been studying um we studied on intro to AI we we studied on machine learning and then we we started with um um few of the of the top algorithms and machine learning we understood what is we understood what's the purpose of whole bringing of this algorithms um and how does how does this algorithms help in learning um which in turn learning in the form of training and and after that learning how it is converted to intelligence right that's the journey that we want to get into we have data um we should build build an algorithm which we has which has some training through which it is learns and then using that algorithm which converts into model uh it sees future data that is unknown and um basing on the unknown data data it will it will predict some values through the intelligence that it acquires right this is the flow so we discussed on the um intelligence learn machine learning we discussed on what are the algorithms what is how does the pattern recognization work in um day three and um how how does um how does the what is the approach of building these algorithms to some extent um it's been discussed so so that being all generalized topics and and those are foundational for understanding today's discussion but let's get deep into linear regression today and um how that has been implemented and um how that um really worked and stuff um so I'll take you through a journey which will actually help you on how um it would have evolved so that people understand um in a much better way uh usually when we read a book we think that okay this somebody very smart sat in a room and uh they like okay pick up a paper and then they started writing everything usual experiments Innovations discoveries don't happen like that people start off with very vague small little bit thing maybe like okay machine learning I'll just have all the data I'll just draw one line and um yeah that that line actually helps in predicting what will be my future values it will be as simple as that this start there they don't come up with um all possible issues that could get into and stuff right so they they start with a wake thing and then

0:5:9 -  they try to do it they see some challenges they they'll fix them they'll see how they are fixing it and then they think of how I can automate it so it's an evolutional process where it refines and then finally comes out as as as a thing which sounds very complex for us but that's a few years worth effort that goes into it so that it comes into what we see and um and obviously because somebody has worked on it for certain years their insight and effort of it makes it little complex but if you dissect it and understand it look through that on what is the purpose of implementing each of them you can connect to it pretty well and it will help you a lot in implementation because you not only know what it is you understand the thought process behind why something like that is being implemented okay that being said um I I'm assuming everybody's set with what kind of thinking that we need to go through let's start off with um linear regression um pretty quickly so um as I explained yesterday so linear regression let's see I I want want to see does this whole YouTube live I don't think it provides anything called a whiteboard or something like that icon window window then okay fine let's not time and then get started with um our document okay um so here I I I thought I I'll cover these but most probably I think we today I I I relooked at things and and thought okay um I know it takes more time people need Pati to understand this whole thing that we're trying to say and all that but while we while we say it um while I say all that one second sorry guys now this will not pop up uh this this become a problem man this become problem I don't know I should solve this again if I share and then I open this it'll work yeah it works so I what I want to do is I want to get to the detail on

0:7:49 -  linear regression um so that people are on board here because um I so for this day is very very important I want everybody to understand it better uh so that uh we have the foundational knowledge and and we we we travel together right so what happens uh we can you guys can we can start with day five there's nothing wrong about it people are smart enough that they can pick up and understand things from there but but the way you interpret the things that we communicate with each other will not be the same until unless we have a common understanding like language right whatever words I'm speaking you you know the language you know what I mean when I say something so we both communicate with each other similarly in machine learning also foundational knowledge if we are not on the same page we are not on the same thinking the the the capacity of understanding or the perception of what we are reading will be completely different so on that context I thought okay let's spend a couple of days more and then get to the detail okay that being said let let me get into linear regression so yesterday we discussed saying um given there is some data and uh the data is represented by certain features okay so for for now we'll we'll assume saying the data has been already given in a format of features like feature one feature two feature three uh kind of stuff so I'll call them features as X1 X2 X3 X4 X5 kind of stuff right so and then what are we trying to derive right the inference are slash prediction will be why where so so you should look at it as like a TBL format right like the X1 X2 X3 X4 so on will be in the columns that are there and then y will be in the one of the columns which is output actually so if X1 is this X2 is this X3 is this X4 is this then Y is equalent to this that's how you you get incoming data and that could be depend depending on your use case availability of data and stuff you gather hug how many records like few use cases you don't have data like Health Healthcare and stuff maybe you would have hardly handful of data like maybe 10,000 records something like that and and some go to financial banking and

0:10:21 -  stuff maybe you'll have millions of Records so the the data set size varies from um place to place okay now as I said um so coming to linear regression what it what it does is it tries to put together um a a either a line or it tries to put together some some shape um some form of form of a pattern that it it draws basing on the points that are there on how they're distributed on the space um which will actually um um that line is our assumption saying uh if if I keep if I pick a point on that particular line which actually represents all these X then this so if you if you take space if you take axis like this and if I put all the X points like this if I draw a if I draw a basing on linear regression is nothing but linear regression is nothing but you should remember it's an equation which helps in uh um drawing drawing a um a drawing a line of different shapes um so I'm not saying straight line it could be a curved line or whatever and that equation is used to that equation is nothing but actually that equation is our algorithm so um so what happens is that line is what is connecting in between X and Y right so for example if you draw a straight line right and um anyways it could be any ways so it's like yal MX plus C right so on that line if you for a given x what is the corresponding y right this is X it comes here the line is here and this is corresponding Y how do you see the value of Y at a certain point like X MX plus c m value of x m into X Value Plus C if you do it you'll get the corresponding y value agree so that's how equations are made like given the input X you put them into an equation you calculate the output is called Y correct simple so similarly what you do basing on his X points that are there you think of it like let's say um as I

0:12:55 -  said yesterday all of the points X X1 X2 X3 are like one comma 1 uh one when I say 1 comma 1 one one is x and y y is one so 1 comma 1 2 comma 2 3 comma 3 or something like that then a straight line would represent it so tomorrow if five comes obviously it is 5A 5 um because Y is equal to X is the equation through which this line is going so 6 6 comma 6 yeah so I can predict it and um I assume that again there is always assum basing on the data that we have I assume that this particular line will actually predict my y values for the unknown X that I see in the future correct is it correct is it wrong we don't know but we are doing it basing on the pattern that is there in the current data and we are assuming that it will be the the future data will be in similar pattern okay so is it 100% correct no because it might not be because people don't know EXT sensibly what is the kind of that data that they are exposed to and if they know what kind of data they are exposed to they need not coming come in for they not opt for machine learning approach to solve that problem they can go for um typical application driven Solutions okay I um I think this pattern and everything I've already explained it yesterday I'm spending a lot of time again repeating it because I I just want you to guys to be very clear but it did not okay um I gave you example of a straight line but it could be also a curve which is which has maybe like X1 X2 plus X3 S Plus X4 any combinations right a polinomial with different degree polinomial with um or something so you can come up with the a different equation and as long as that equation helps us for a given X to predict y we that is actually the right algorithm that we want to use and that's what is the algorithm and which eventually becomes um the model which predicts why that's it so did I make it very simple I think so but that's the right thing and if you if you look at the whole machine learning algorithms models so-called complicated terms it boils down to simple math and uh it's a math equation especially talking about this linear regression and

0:15:26 -  stuff but um even if you go to complicated things tomorrow like let's talk of decision trees let's talk of random Forest let's talk of um um svms let's talk of uh neural networks let's talk of U Transformer architecture anywhere you you you go there are different approaches different kinds and all that stuff but everything boils down to a mathematical equation where the objective of the mathematical equation is to derive y basing on x the representation will be different the um the instead of using one equations maybe we'll use multiple equations um the combination of equations um are um um are there are different approach on how the equation needs to be derived um how the see like as I said X1 X2 X3 X4 you can you have multiple combinations like I can say W1 X1 + W2 X2 + W3 X3 is equal to y or you can say W1 X1 s + W2 X2 s + W X3 squal to Y that's also possible so there are multiple possibilities when I say equation could be have and number of permutations and combinations right you can just simply say X1 into X3 into X4 into X5 is equal to Y everything is possible so the complexity comes into what is the equation right equation that I put here which aligns with the X data that is there and also gives me proper y okay deriving this is the most complicated thing in the whole machine Learning Journey um and the equations need not necessarily be linear as I said they are when I say linear the the linear equations are the one which fall under this linear regression um and similar things will also be used in logistic regression um similar things will also be used in uh neural networks um so there there if that that's the intent of calling it as a linear regression okay we we should be clear on it but how so let's get to the detail on how do we start off okay so because we talking about 1 million records if there are three records and if the three records are X1 sorry X1 why is it going okay

0:18:31 -  maybe X1 oh okay whatever X2 and Y okay and let's say if it's one one and uh four or let's say one for for Simplicity I'll say two okay this is getting into the Tabler format that's the challenge is okay one right so similarly let's say two two and two right so four 4 four something like this and X1 as I said typically people take linear regression they take Only One X so that people are not confused or something like that but I want to I want you guys to be realistic there there's never saying okay given One X predict y that's that's easier right so there's always multiple features and if there's one feature feature and then that's that that you know of a product and then you want to try to predict why it's a simpler problem to solve but um the scenario is always you have multiple features but how do you deal with it um as I said so if if it's like this saying uh this is X1 this is X2 and you not to predict y so so it's it's three dimensions right the x is a different dimension X2 is different dimension Y is different dimension what we do is we we bring in the we project the X2 onto the X1 surface that is the the values that are there like this the equivalent value of it will be projected into the x axis here so we we combine these values like this and bring both of them to same plane assuming again it need not necessarily because it depends on the scale of the values because um this is complex and import it comes in when you do explor Tre data analysis and initial data processing and stuff this could be the um this could be the width of the if you're talking about a table right so table has legs and then it could be width of the legs so it usually would be in in ctim or inches right this could be cost of the table okay so this cost of the table could be $200 $300 and stuff but whereas if you are counting it in here in inches it will be less than 10 in something like that right far less than 10 in because we're talking about width of the table so when you project

0:21:3 -  it what happens the width is here in the x-axis right it will be 0 to um so 0 to 4 or 0 to 5 whatever but whereas the prices could be varying High here right so what we do is to project it here onto the same plane we um bring them to equalent values we we we scale them down so that both of them are on equalent value so that they can represented in the same same space and those values could be mapped to Y seamlessly or else if what happens let's say you have the width of the table in in 0 to 5 and the price ranging in 100 to 200 or something like that or 50 to 200 kind of something like that you you can't practically put an equation which will actually say okay for the line will go like this and so let's say you want to do a straight line it's impossible right because few of the X are here few of the Y are here you you should draw a line like this which doesn't make sense right because both of them are far apart so what we do usually is that's a that's not an important topic now but just because we are having a context and explaining but I'll we can go into the detail when we solve some problem hands on some sometime later but we bring down this x we we scale down both both of them to one level so that all those points are here so it's basing on scale so like for example if the range of it is 50 to 200 I'll make 50 Z and 200 as 10 so R 200 as 1 so what what will happen all this 5 to 200 points will boil down to 0 to one range similarly what I'll do this 0 to 5 in width I'll scale it down to 0 to one so what happens now in this space I have everything in between 0 to 1 it's your choice you can make it 0 to 10 anything but if I scale it down to 0 to 1 all the points are in same space now if I draw a line everything goes through the same points agree or if I put an equation any equation I have similarity between that's how you bring down everything to One X so X is is you can actually look at it like capital x here I should somehow make small X uh capital x I mean just for representation purpose I can say It's a combination representation of

0:23:40 -  X1 X2 X3 so on okay uh now let's let's talk of um picking up something right so next thought process is okay I have it I have y I want to understand the pattern uh I want to come up with a pattern which will actually map the given X to Y and there are a number of possibilities correct how do I make a choice what to do like how do I make a choice on what equation to use but let's talk off let's start with somewhere right because if you start that's a complex problem saying okay should I put a line polinomial what degree what combination X1 X2 X3 x¬≤ x¬≤ plus X CU + x the the list is exhaustive you can have there are millions of things that we can think of when you think of something like that so the question comes is let's start off with something and let's take baby steps on if I start off with something okay as a random choice so how how far that will work out how far that's um right thing to start off okay let's say we'll put it we'll make it very simple we'll assume that like like the points here right this very much indicate for me saying yeah there could be a linear I can put a straight line and I'm good with it I can I can predict values basing on it okay so what I'll do um I'll put a straight line okay now I'm looking at these three points basing on these three points I can actually say it is a straight line which is more like y equal to X kind of a straight line right um or it could be y equal to WX uh W1 X1 or something that right so we don't know it could be any but it could be a straight potential straight line right which will go through the these points now when I put this straight line um there how do I decide that straight line is the right algorithm for the given points so for example uh let's say I pick up a line LOM line like this Y is equal

0:26:26 -  to um 3 X1 + 3 X2 [Music] c um I can't say C I should I should have clear value for it let's say let's leave it like this like 3x1 + 3x2 okay now what happens um if I go start putting these values here so this is y that is given to us and this is my y that I'm predicting through my uh through my equation right the equation expectation of the equation is it should be able to predict this y right so here if we start putting up values into this particular table what happens so this is y and let's say this is y predicted right so I I'll put small P okay and [Music] um what will be the volume so if 1 comma 1 is put in here the value is six if I keep um 2 comma 2 it becomes uh 6 + 6 12 if I keep um um 4 + 4 then it'll become 12 + 12 24 right so the actual expected value is 1 we got six x expected value is two you got 12 x expected Valu is four and you got 24 so what does it say is um okay as I said people would have started like this right they would have thought okay why not just pick some number and then equation and that will predict it but they would look at this values and for you you feel yeah it is wrong y p and Y are not matching the expectation is why and YP are not matching so but these three things because you're looking at it you're able to say but what if there are million things how will you look at them and say they are right wrong or something like that right it's not possible so what would people do is they don't have another choice but they say okay there are million records but how many of them are matching and how many them not matching first thing right okay for for those are matching good we did a

0:28:58 -  good job our algorithm is great it's doing good and stuff but for for things that are not matching what is the difference okay what is how much is the difference right and what should we do about it for example in this case if you look at what is the difference it's expected is one it gave six so 6 - 1 is 5 and uh expected is two you got 12 difference is 10 expected is four you got 24 that difference is 20 so that's the difference right uh so the difference that we see here is actually because of picking up this specific equation the difference that you see is actually not a difference between what is should be actual value of y and what is the predicted value of the Y that difference is nothing but the loss of Y right by is supposed to be one and it became six so you should look at it as the loss is 5 similarly for 2 and 12 the loss is 10 for um 4 and 24 the loss is 20 right so what we need to do if the loss we need to try to reduce it agree so 1 and six if if it if it is five now if you reduce it to four you reduce it to two one and something like that the loss is smaller correct so you're coming closer to so the Gap in between Y and YP y predicted you should reduce it as much as possible so that YP is is closure to y or YP is same as y so that the prediction is what we are expecting so this is what the difference is called loss okay so that loss is calculated like this um so people say the there's a loss there's something called a loss function so again where we are heading instead of Simply understanding all the terminologies and stuff your thinking should go how far is YP from y I want to find out so that I can make a decision right saying okay YP is is this far from y so now I say my current equation is

0:31:43 -  this bad it's like you have a algorithm you have a machine learning model and that that that's this bad if you classify it you you know how much it is bad you you know how much to correct it correct if you don't know how much it is bad you can actually assume saying okay yeah 3X plus 3x1 plus 3x2 is perfect it it fits in perfectly into what I'm expecting so I'm all good no it you are not right it is it is not correct so uh because the um loss shows me saying your loss is high right and um again that's another thing that people should think about how does somebody predict loss is high or loss is low um so we don't know all we try to do is reduce the loss at some point we should we should agree everybody should agree and and loss making loss zero is also not the right thing because um we'll discuss more about it later on I don't want to give you more things at this point of time and um complicate things but let's try to make it as simple as possible right so uh this is loss I I I want you guys to understand what the loss is and um so for in this case C function would maybe say um we can say sum of ifs above right um but what would happen is what if the points are negative right minus 3 - 3 and let's say minus 3 then what happens your YP is - 18 and if you see Min - 18 - 3 will become - 21 this looks like the difference in between the loss between -3 and -8 is -21 but actually it is not right okay uh my bad um - 18 - - 3 is -5 okay U so -5 looks like um is is actually the loss but if

0:34:24 -  you if you look at it U from Individual row it is correct but when I do the sum of difference what happens is the loss of this function will become 20 5 + 10 + 20 + -5 -5 will remove 10 and 5 and then 20 right but and this appears like it has lower loss compared to only having these three rows correct are are another equation because this is not correct thing because so what people do some of the above loss function doesn't give you the actual loss so this is not good so we need to represent it in another ways one way to represent it is um we can go for um we should go independent of the the problem that we see here is oh there are signs so plus and minus so we are looking at plus and minus there counting them as plus or minus doesn't make sense so let's just um get rid of the plus and minus right like up apply a modulus operator and make them all plus so like you can say mod difference right so then what will happen is mod difference is five 10 20 15 okay so this makes um perfect sense right so now the sum is the sum here in the previous case the sum is actual loss the sum is 20 but now in the new if you apply mod on top of it the difference is the sum is 50 so this is shows my loss in a proper better way then than the other case because the other case is deviating from the actual loss that is there kind of so this is lost function so um which is which is good so these two I think we are clear on um what is the loss function right but let's say these two records are not there the the 20 and 15 is not there then the L function value is 5 + 10 15 correct what if I have three records 35 what if I have four records

0:36:59 -  like like here right it's 50 so the number of records that I use in order to calculate the loss function is impacting my loss function so it is getting dependent on the number of Records so today let's say we have 10 records we we we run our algorithm we create a loss function and we look at it okay it is 15 good tomorrow what happens we we we are we are like we ran out of time and we should go home and all that stuff and then we sto doing things tomorrow when I come back for some reason somebody could somebody who kind has given me a few more data sets for my training right so I put them so what happens my L suddenly it increases so I'm like okay now I should Chase 35 instead of 15 and I need to bring it down right the the whole objective is to bring it down so okay I'll work towards it I'll do something maybe I'll bring it down from 35 and as we get more data the L function will keep growing and then we we need to keep tweaking the things so so L function is not relative right it's not I can't compare in the first case also my first equation that I had on the first day with 15 to second equation I have 35 50 it's not comparable so what should I do I can't go with this right so what I'll do is I have I have loss for each of the rowes instead of considering the sum of it some of the losses if I look at the average of this losses it would be much better correct so for example the firstday if I look at the average 5 + 10 + 20 5 + 10 15 by 2 it's 7.5 the average of the next day is 3 sorry 35 and it is 3 records so it is um somewhere around uh 11 uh 66 or something like that and the third date is 50 and there are four records so it's 12.5 right so this is average still it shows it is increasing but that's the right thing because um that actually is more practical um but 15 to 35 35 to 50 is actually a huge jump but whereas 7.5 to 11.66 and 12.5 is actually practically

0:40:5 -  correct because the numbers are really the new data sets that are coming in they're giving me more differences so that's practically correct but these numbers are more realistic and U they I can rely on those numbers than the individual sum of the numbers correct so we need to do an average of the loss functions right so which is the right thing to do I'll uh um this takes us something to our next so this is classified as loss function why do you have so many functions I don't know but people would have this is an evolutionary process right like people had a people had X and why they put an equation okay given equation how do I see whether it is right or wrong okay try L function they tried function as some of differences theyve seen that the the differences are some of the differen is not proper right it's it's being influenced basing on the incoming data um it should not be influenced by the incoming data it should not be influenced by the number of data set examples are there and stuff right they they slowly realize then they said okay let's make independent of the sign right they applied modulus and then they said okay basing on number of data sets it's influencing so let's make average um um so that's how they evolved and finally from LA function they came something called cost function so the cost function um let's look it up here also explain um yeah so good I think I should I I should use this more uh than instead of getting tired on that okay um question why do we use [Music] squares the cost function instead of using modulus model differences using the square of differences in the cost function mean Square rather the absolute difference as in mean absolute error okay that's Ms has our advantage in the context of linear equation many othering differentiability squaring the differences makes the cost function differentiable

0:42:36 -  so as as I said so we we in in our flow we have arrived till here right 1 by m that is we said average or mean and uh of some of the differences okay um and we thought our equation is Sigma I = 1 to M and then we had modulus of Y and Y PR this is YP or YP right y minus YP modulus is what he said which he uses the term mean um absolute error right that's what we came to but instead of using mean absolute error the the cost function uses here mean square error msse right so um why is this a better metric than mean absolute error so for that he has people again they would have experimented with these things and um and it it works backwards also at times that okay mean absolute error is good let's move forward with it in the further steps when they go forward they do other things right so loss function is just an indicator basing on the loss function they should take some decisions with respect to especially with respect to the algorithm saying okay the algorithm that we had uh 3x1 plus 3x2 again I think the the Pix is 3x1 + 3x2 is equal to Y is is wrong so I should correct it so how do I correct it so I should change the variables that are the variables are nothing but three and three right 3x1 plus 3x2 I should change them how do I change them so these are the further steps that that they do but in in those further steps they would have encountered okay um the mean absolute error if it's being considered as my cost function the calculations that I do here is complicated so how about I change the mean error can I can I change the mean error in a way that it actually makes my calculations easier that's how that's how people would think so is it the right thing the cost function being mean absolute error is is correct it it it actually represents the loss you can actually look at it and then say you can compare in between different data sets and say this is how it's varying um but people make a choice as I said it's it's not only about whether it is right

0:45:16 -  representation or wrong representation it it also boil down to the Future scope of using that particular and um where there's for example differentiability so um so squaring the differences makes the cost function differentiable right so that's one thing so let's not get into into the detail of it but again it's again it's it's more related to mathematical equations that we going to go through later on it's it makes it easier if there's a square okay um he says it has sharp Corners what does it mean I don't know amp on large errors squaring the errors amplifies the large erors more than this makes more sense like so what happens is five and 10 for us it looks like we very close but if you square them what happens one is 25 and another is 100 and so 100 sounds like a bigger problem for us right and compared to 25 right so that's they want to emphasize on the large errors it same so that's that also makes sense mathematical Simplicity squared error function has nice mathematical properties that that simplify the derivations of optimization algorithm antical solution okay again they're talking about derivations getting easier statistical interpretation the use of square and the cost function is related to certain statistical assumptions such as go and normal distribution of errors in linear regression minimizing the squared errors is equalent to maximizing the likel of observed data under the assumption of normally distributed errors okay so these are all the reasons on on further steps when they do uh when they cost function they take decisions on how the linear regression is to be changed we'll go through the remaining steps also but in those steps they observed saying okay if I go with mean absolute error and and if I do all the math math calculations and all that to see the difference for me it is getting complicated so can I this um cost function without losing its context that is as I said the number of um dat the the size of the data set are the individual values of the data set should not impact the cost function that standard being kept intact if we can change it so that the math becomes easier um because again the math goes into solving the problem the

0:48:3 -  Sol this problem ho get gets into computation and that should be run on a computer and that will take if it takes more time then what happens you you you should wait more time for training your model and that in turn takes more cost So to avoid all that people come back say Okay I want to reduce the cost so people would have done all this and then like dude your machine learning is taking lot of time so let's reduce it then they said okay let me optimize it right so then they say okay where can I optimize it how about my um um equation um fine-tuning my equation or something like that could be I could make it faster maybe the calculation should be faster how can I make calculation faster maybe instead of using mean absolute error use mean square error and my calculation is faster so uh I I know I'm I'm trying to um give you a use case which is futuristic but I think you you guys should understand the thinking process of people and why they have arrived at mean Square okay so that's those are the reasons why instead of um again I need to stop and come back and then do this but sorry for that guys now if I open it so what happens the cost function in in this scenario oh this this is tough for me but I'll just say 7.5 uh Square comma 1 66 Square comma 12.5 Square so the cost function is nothing but the sum of of square difference between Y and YP so Y and YP okay uh so cost function will give us a metric to say okay if these are my points this is X and Y and if this is the equation that I'm going to use cost function tells me what is the overall loss if I use this equation as my model this equation as my algorithm for learn training and after training if I deploy it as my model to predict y for given X this is my loss or this is my cost that

0:50:36 -  I bear uh if I if I do it and people needs to decide um our data scientist needs to sit and data scientist with other people they they discuss and decide okay this is my cost function values and stuff so this is the kind of loss that you will see if you if you use this um kind of a model models are usually are like 80% accurate 90% accurate and stuff when we when we talk of all this loss function and stuff when you say 80% accurate that means it is not 20% it's not accurate right and even though that means 20% of the cases when the data comes in it will give you something wrong and there should this should be agreement saying right BAS on the domain use case that you using and stuff you should agree on saying yeah I understand that um 20% U there will be mistakes and my business can live with it right so and both of them agree and then to to communicate this like what is 20% is it 20% 15% 5% that is where this function will come into picture and say that that's the amount of impact that um relative impact that it will it has and it will um if people are not okay with it they try to reduce the cost function the the more you reduce the cost function the more Y and YP go closer to each other so the overall prediction capabil will also increase okay so with that being said we covered linear regression um with respect to how what is the equation how to calculate loss function how to calculate cost cost function and stuff but we didn't go to The Next Step that is how do I fine-tune the algorithm and make it much better how do I pick up my next equation that's my first equation which is which we think could be a random guess of what it could be um but how do I find tune it um to get an equation which is more closure which reduces my cost everybody should use the same language which reduces my loss or which reduces my cost how do I derive to my next equation which is closure it did not be bright fit into y that is not possible okay everybody should be on the same page it's not possible saying okay this is my cost okay let me change this and I I'll become I'll make ypy not possible you actually go can go closure