# Day 26 Study Time Gen AI

# Day X: Study Time on Neural Networks and CNNs  
**Time Interval:** 00:00 - 39:00  
Summary  
- **üîç Overview**: The session begins with an introduction to **neural networks**, detailing their equations, optimization methods, and hyperparameter tuning. The instructor outlines plans for hands-on programming exercises to consolidate understanding.  
- **üß† Neural Network Concepts**: The instructor explains the basic architecture of a neural network, including input, hidden, and output layers, along with activation functions that determine the output based on inputs.  
- **üìä Focus on Hyperparameter Tuning**: Although a discussion on how to tune hyperparameters was planned, it will be handled programmatically in future sessions. The importance of hyperparameters in machine learning is emphasized.  
- **üåÄ Introduction to CNNs**: The instructor shifts focus to **Convolutional Neural Networks (CNNs)**, explaining their role in image processing and detailing various essential concepts such as convolution, padding, and strides.  
- **üî¨ Convolution and Padding Explained**: The session contains a deep dive into the convolution operation, detailing how filters are applied to images to extract features and highlighting the significance of padding in preserving input dimensions.  
- **üìâ Pooling Techniques**: Maximum and average pooling are discussed as techniques to reduce image size while maintaining critical features. The difference between them in terms of image intensity retention is highlighted.  
- **üîé Practical Applications of CNNs**: The instructor illustrates how CNNs can be used to detect specific patterns such as vertical and horizontal edges, underpinning the importance of filter size and layer configuration for image analysis.  
- **üöÄ Next Steps**: The session concludes with a promise to explore backpropagation and further intricate details about CNNs in the next class, ensuring that foundational concepts are well understood before progressing.

# Transcript 


0:2:36 -  hey hi guys um today what we have covered is neural networks we went to the details on how neural net work what how is the equation form what is reg optimation and then we hyper parameter tuning the we we looked at what are the hyper parameters but we didn't look at how the hyper parameters can be tuned and stuff what we'll do we'll programmatically look at how the hyper parameters can be tuned we'll take a sample data set and try to put hyper parameter tuning on top of it to see understand more okay matter of fact uh objective is to allocate one day where we actually program the whole things when we'll not program from the scratch but we'll just use the libraries because libr are pretty easy and we'll use CH GP to generate the code and then R it just for doing a demo of it so um I think that will be a good recap of what we have learned uh and what we apply now stuff so it'll be good we we'll do that and um okay today let's focus on CNN I started already studying CNN um yesterday and a little bit like last two days and stuff which I didn't put it on video but I do it I might be studying more might not be able to watch much but let's see okay so we actually watching on YouTube um so this guy quickly explained conv n NS so I'll brief about my understanding till now because um it was actually it should be more focused I'm not done that but it should be more focused but this guy has explain it pretty well there are three things one is convolution padding and strip what is CNN padding and these are the three concepts here to explain let's start with CNN CNN is primarily okay Ann is artificial neural network okay now from there what is CNN is a convolutional neural network artificial neuron Network what we do we we have input layer and we have hidden layers and then we have output layer we pass the inputs to the hidden layers and then hidden layers will process them and give an output to

0:5:16 -  the output layer okay even hidden layers and output layer will have a function activation function which will actually give certain an output okay conation neural networks are nothing but [Music] um they are specifically designed for image processing Purp purpose as a primary intent they can be used for other purposes also but primarily they for image processing purpose um what does a convolution operation mean is um Prim my understanding is it's these are if you take an image of n by n pixel usually images nowadays with this highend cameras on Apple phone and all that stuff right so they are we we receive huge pretty big images correct so that big image is being fed as input that means each pixel is one data point correct so for to give one image as input to neural network you should send all the pixels let's assume if you take 1,000 into 1,000 pixels that is th000 length and th000 width pixels to represent an image right then you have literally 1 million pixels to one image you need to feed in 1 million pixel input data to a neur network and ask to process it what happens is it becomes very complex with respect to calculation computation and stuff so so what happened here in neural networks concept we inputs are features right like F1 F2 F3 F4 and stuff in a given image what happens is assuming images of same Dimension are being given each pixel actually is a feature that means literally image is nothing but it has 1 million features because we don't know which pixel represents what Right image you not necessarily means that the face is on the center right the fa is could be on the corner on the left on the right it could be some Edge uh there could be a car coming in the

0:8:11 -  edge so we don't know there are a lot of things a lot of detail which could be anywhere in an image image can never be defined right so every pixel is important and um but processing 1 million pixels or more with higher resolution and stuff if you consider is um it's a hard task right agree so because we can't do it that way what we do is we kind of um go for a like like principal component analysis where we uh create an feature which is effectively similar to other features right so we we kind of the feature from the existing features and we use that feature for or feature our features for your algorithm contion networks is also on a similar lines where what you do is quickly if you can see so we take a filter like this and we we move that filter on top of the image this is an image with the 6x6 pixels so you move a filter on top of it and then you as he has shown here calculation you multiply each of this numbers with these Matrix numbers and add them up like 6 into 1 5 into 1 7 into 1+ 9 into 0 1 into 0 4 into 0 plus like that and you calculate the effective sum of this filter on top of those numbers and then you derive a new Matrix out of it which is um because this is 6X 6 we keeping a 3X3 on top of it what happens is these three again these three again these three again this three so there four right you you'll get four similarly this way also four so it is a 4x4 Matrix that's how you get he gives a formula out of it but it's okay so what happens basing on this now the another point that you need to look at is the filter right so look at the filter there are some numbers here 1 1 1 0 0 0 -1- one- one so this has a significance but I think we not yet looked at how do you put numbers here like you so you should decide what size of the filter you should pick up what should be the filter's um values uh those those we should still learn it but as for this guy what

0:11:47 -  happens is [Music] um this filter will actually help in ding the vertical edges um B says these are all vertical edges that means vertical straight lines horizontal or horizontal is also there right so how come this line has come then he says vertical this is not supposed to come correct hor vertical should be straight lines okay let's see why it is vertical and if you use the anothers filter it gives you horizontal edges yeah so 111 - one so this gives us horizontal edges is what he is saying I I think it is more on um the First Column is being considered the third column is making is reducing it so if there straight line here and if there's no straight line here then you'll have some value here why is that what's the logic in this how does it give vertical edges let see here what B you can see the difference [Music] the horizontal lines which are actually kind of parallel to xaxis those are all reflected here here those are all which are parall to Y axis has been reflected but how did it happen is a mystery what are we doing when we multiplying and keeping those numbers one into something if these three points are some if it's just vertical straight line what will happen these three like let's say here somewhere vertical St this one vertical slight L these three points will have RGB values higher right than this ones when it is higher multiplying them with 1111 will give a bigger sum agree for this pixel but if this [Music] pixel and let's assume there's a pipe like pipe light kind of stuff so if this is also there let's take a pipe and then put a filter let's say one edge of the pipe is here one edge of the pipe is here this

0:15:50 -  will remove this and will make it will become zero two vertical edges if they are there it's becoming zero then how does he say that it detects all the vertical edges most probably I think that is the reason this other side of the vertical Edge is didn't coming up here but we need to get to the details so this is open question still how come this gives vertical edges and this gives horizontal edges you didn't explain on it much let's look at here I so that's with the filters and then how the filters are applied and we calculate something but the objective is to reduce the whole fil whole image from n byn to U basing on the filter size it'll become as said nus f + 1 uh and uh into nus F + 1 okay where n is the image size f is the filter size okay then that's convolution so that's how you are reducing the size but what he says is padding concept if you if you observe each box when it goes through it here not this one here if you see the filter when it is going see this one box if you look at it 1 2 three are are picked right so observe the one box alone oh it is gone okay next time it goes 1 2 3 239 at least the two is considered twice so whereas one as because the filter is going this way the one is being considered only one one time similarly the nine also will be considered only once see at the end box 698 this line is considered only for this calculation it's considered only once so the influence of the first row of the image and last row of the image on this filter because we are moving this way is only once whereas 1 2 3 2 39 2 is coming twice 2 39 3 98 so 1 2 3 2 3 9 3 98 this is

0:18:36 -  giving three times the effect of um three so the number of times this particular IM influencing the image um especially the ones on the border is is is less because of which it's actually has a it actually has a lower implication on um the overall convolution image convoluted image that we creating correct so yeah as he's seeing here this particular image if you look at it it is coming on one four times whereas this image is not coming so many times so what we do is we do a padding so that the the blocks start from here and this image becomes internal image not the edge and these Edge ones might be considered once or twice but the internal ones are repeated multiple times now if the filter goes see this image is on repeated like four times so this this padding is called um technique is called valid and same padding so valid padding is [Music] uh where you go with without you go without padding so whereas same convolution padding is where you add padding in a way uh okay yeah valid convolution is no padding same convolution is where the output of the padding will be giving the same image but this raises another question saying the objective itself of doing convolution is to reduce the current image to a smaller size because it the image itself is huge so you can't use the image as is is the concept so but if you come back to same image Direction it doesn't make sense right [Music] so but let's see what will happen in the remaining when he explains the remaining details kind of it strides are nothing but you are moving 69 and then it becomes 69 10 then becomes 9 102 1028 285 right this is how you moving one pixel at a time and then you moving this filter right so that that movement of one pixel is is stried so if you move two pixels then it is two strides that is

0:25:16 -  169 it it moves here then 9102 and then it moves here 285 so what is happening six is being calculated only once right so you can actually see this guy will show you strided convolution so if you do it like this so gu is on so 169 then stri two if he takes it what happens after 69 the Box becomes 1 to 9 see 9 10 two six is only counted once and also another problem is this something there go down so this line will not be effective TR that's for the SL for I good Happ know so there are two kinds of pulling that could be done so that means again convolutions is where we are actually applying a filter and we are reducing we tried reducing the size are it's it's not trying reducing the size we tried to actually extract some features basing on the filter that is being applied and you can apply multiple filters the objective of convolution is really to identify features for example uh from a given image list of veral lines list of horizontal lines list of circles to retrieve all hor all vertical lines they we use one filter and we extract all the vertical lens and we make it one image now for horizontal lens we'll make it one image for all circular pieces we we make one image so for detecting patterns like this within the image we are using filters filter goes over the image each using the sides and it picks up the corresponding feature and those features are separated out so you're breaking down the bigger image into smaller images basing on the specific um feature like vertical line straight line uh circles blah blah blah so how do you pick up filters how does the filters pick up these lines and stuff we I think

0:27:47 -  we'll learn that's an open question we should learn about it now the max pulling size is so um what happens the are two kind of pulling uh and and if you look at the layers they are not part of the neural network layers as I said they are like pre-processing before giving it to neural networks is first the convolution happens and then we can give it to pooling but it is not mandatory that we need to give it like that but to reduce the size of the pooling what we are doing is usual pattern of the images if you look at it if you look at any images most of the images are having similar pixels in a region for example if you take this um for example if you take this watch this whole if you if you think this is an image the blue color most of the blue colors are close by right so what I'm doing is few of these Blues I'm adding them I'm taking the if I keep an image like this here on the border which has this blue color and my skin color and stuffff at the border whichever is the darkest color for example if my skin is dark skin are area in with the filter is is the dominant one then I'll actually give Max pooling Max pooling and average pooling Max pooling will give you whichever is the more intensity so let's say my skin is the more intense one in this particular region I'll keep my skin color there and I'll remove the remaining three okay if blue is more intense then I'll keep the blue I I'll remove the other colors so what I'm doing I'm reducing by filter size I'm reducing those image and replacing it with the darkest color for example if you go here if there's black here and um and the reming are lighter it will pick up black and then go by the filter so what happens this whole size I'm reducing it down and actually I'm picking up whichever is the bright colors there those are the bright colors I'm picking it up so max ping is to reduce the size of the image basing on the filter size it will reduce by certain amount of size you can make it a half or whatever but um does it have the level of detail that is there in the initial image no it it will reduce

0:38:26 -  the level of detail that is there in the initial image uh but because we want to R we need to reduce the image size we are doing this at the same time what we doing is like if there is a blue color that is distributed like this out of this whole blues if you're picking up the maximum blue value there the this the blue which is of lower intensity those will go away then what you'll end up is even though the the image size from this is reduced the the blue will become all the darker blues will put be put together so this will become darker so the image will become more intense or brighter so you can actually look at it much better than the previous image agree the size and stuff it might vary but uh the image quality becomes you it becomes more sharp because you're what you're doing is in a given image you're removing all the lighter Shades one and the and the higher shade was can be retained that's Max bowling is where you you retain the max intensity one whereas average pulling is where you average if you get blue intensity once out of the four out of the four blue intensity instead of taking the Max and then saying very bright let's say there's only one bright and the other ones are all small then we take an average to show that this is how it is so it doesn't really give or make us believe that it's very bright it says an average say all Aver this is the brightness of this particular so um again same question on how do you pick up um max or average one question pooling second is the we are using a filter here how do you pick up the filter size so no parameters Alm no train same number of channels in output as input uhh than for thank I [Music] I you y see okay for I think you that's I for

0:51:47 -  I I every I for okay okay what is this now so you break it down into 3x3 Matrix into 2 by2 of uh 1 2 three four four parts we breaking down to four parts and then four parts we are um using passing it through it's like we breaking down to four parts and we passing it to four neurons four neurons will apply the with same the same weights they'll apply a linear regression kind W1 X1 plus W2 X2 plus W3 X3 and um the bias term and Zend it that means we are breaking down a given image basing on the filter size we breaking it down into so many images n minus F + 1 here it is uh 3 - - 2 + 1 that is 2 uh 2 2 into 2 like four um and the four Images will in turn be passed through four neurons technically that's how it is okay I I e it I [Music] body [Music] [Music] BL [Music] [Music] [Music] s [Music] [Music] J [Music] that [Music] know spe [Music] [Music] spe [Music] spe for I think we'll pause here back propagation of looks we should look at it one more time to be more clear on how it is working and