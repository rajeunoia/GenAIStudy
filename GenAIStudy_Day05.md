# Day 5 Study Time Gen AI

# Day 4: Study Time on AI Concepts
**Time Interval:** 00:00 - 37:25  
Summary
- **üîç Overview**: The session begins by recapping previous lessons on **AI**, **machine learning basics**, and **linear regression**, with intentions to complete linear regression and initiate **logistic regression**.
- **üìê Linear Regression Review**: The instructor elaborates on **linear regression**, specifically focusing on recognizing patterns, formulating equations, and calculating potential outcomes.
- **üß† Understanding Loss Function**: The significance of the **loss function** is explored, detailing how to compute differences between expected and predicted values to evaluate model accuracy.
- **üõ† Cost Function Calculation**: The concept of the **cost function** is introduced as an extension of the loss function, detailing how squared differences are calculated to improve model predictions.
- **üéØ Model Optimization**: The session emphasizes the need to adjust parameters (W1, W2) to minimize the cost, with discussions on systematic approaches to optimize the model performance.
- **üßÆ Introduction to Gradient Descent**: The instructor begins explaining **gradient descent**, a technique for adjusting model parameters in the direction that minimizes cost, laying a foundation for further discussion.
- **üöÄ Looking Ahead**: The session concludes with a preview of further exploring **gradient descent** and its critical role in the optimization of machine learning models in subsequent lessons.

# Transcript 


0:2:46 -  hey um hi everyone so um this is this is day four and um we are going to um what we have covered is the intro to AI um basics of machine learning and then we picked up linear regression um and we covered it a couple of days um we didn't really complete it yesterday so we'll try to complete it today as much as possible and um we'll also try to see if uh we can start off with logistic regression today um okay so in linear regression what we learned is um how to recognize the pattern which is the underlying Theory we should come up with an equation and um if we come up with one specific equation where the um variables as in let's say we thought W1 X1 and W2 X2 and then we thought W1 and W2 if we take random like random of 0 comma 10 or something that and take some random numbers there and we put it as W1 W2 and then we process it how do we determine whether it's correct or wrong so that is what we we thought we will do and uh we in the process we said okay there is something called how to calculate loss so we identified how to calculate loss okay let me show the document to assuming the is open yeah so WECT this XY um and U we thought let's try this particular equation uh now it is confusing so 3x1 into 3 + 3 X2 and then we have observed what is y expected Y and what is predicted by what is the difference and um so how how that difference can be calculated in more efficient way so called loss function which is sum of differences um in of sum of direct we should we thought it's better to do some of model differences so this all we calculated and then um instead of taking sum of differences we um we go with the mean of these differences so that it is not impacted by the number of data sets number of um size of

0:5:45 -  the data set and um then we also looked at something called a cost function which is um which is just extension of floss function but only difference is it does the sum of a squares okay I suppos to this so which is supposed to be uh sum of the squares so um mean of su of the squares so we we we looked at look as ch ch GP told us uh mean absolute error is is what we have calculated here the mean of these uh numbers absolute error and uh this is mean of um uh by the way this is wrong this is not right this is actually this after calculating mean we are subtract it but this is wrong this is not because cost function will will be the core differences that are there these okay so it will be 5 Square so okay let me write below the cost function itself so that it is clear so it'll be whatever is the differences that are there those differences will will Square them so respect of the sign it will be same because anyways we are squaring it so the the negative sign will go away um so it will be 5 square + 10 s + 20 [Music] square + 15 Square averaged by number of samples it is four so cost function some of square differences between Y and YP mean of sum of square differences between Y and uh so this will [Music] become um 750 by 4 which is uh 3 75 by 2 um which will [Music] be 187.5 I hope the math is correct but

0:8:22 -  anyways it's fine [Applause] um so that is the actual cost functions cost so the you can actually see for from terminology perspective to this is this is loss function um as well as this is cost function um and we also looked up at to see what does the cost fun why does the cost function do us we did a modulus here and we ared this number why are we not sticking to that why are we not using just that um why are we doing a square we we looked up and then it said so further when you go down the line if you want to do a differentiation of this equation or if you want and if if you want to focus more on on the variables which has high differences like like like we want to reduce 20 and 10 in the first 205 and 205 On The Higher Side this s to you amplify right so here if you see it says 2500 400 225 so 400 is really pushed it pushed up so that you see okay 400 is a big problem let's all so the target is to solve the bigger problems there and then we address the smaller one on uh accordingly so that differentiation will be there um uh that's the reason they they do a square of differences um so we we'll understand more of it why why we did square of it when you when we do the follow the next steps um to see how it works and stuff so now we know the cost function now we know the base equation and stuff so this is what we had this is the cost and uh let's say we are not happy with the cost we want to reduce the cost or we can think in this Direction I mean obviously everybody wants to reduce the cost because the more accurate it is much better sorry it would work but if you look at it in in two directions so today it's going to be like this 10% charging is there so um today being a weekend maybe we'll go a little shorter so we'll and try to be faster also because recap itself has taken this long um so now now but this is this is important very important I would actually spend more time on this because uh people jump this people don't spend enough time here and uh they they they move forward they'll do things but

0:10:53 -  always these questions will go go in their mind one time or other time they they'll come into situation so okay how did how did the loss function come how did a cost function come um and and you run an algorithm and it starts telling you this error that error like mean square error mean absolute error and this is the cost and all that and you don't know how it is calculated so if you don't know how it is calculated how do you take a decision whether you want to train it any further or do you want to stop or what does that mean if you don't know it how do you use it right you you can't just say mean square error equation is this that doesn't help right because even if you calculated error so how did it take a call on on on saying um if you call this W1 X1 plus W2 X2 how did it take a call saying this W1 W2 is the right thing right so these are all questions that are be left with and your decision making on picking a right model will vary basing on this information right agree so that is the reason you need to know all this or else you go ask chat jpt give me an you give me a python code which will actually run linear regression for me just there are libraries every damn library now in uh can has the excuse me guys sorry has the logic to implement linear aggression so that's not what we trying to do we not trying to implement linear agression we're trying to understand how how somebody has evolved how someone has or group of people has evolved linear regression from the start till what the final process is and what is the thought process they have gone through so that not only about linear regression but any kind of a model that we are building then we can actually use similar thinking so my my output that I want you guys to learn is not linear regression not machine learning not AI but the main intent is for you guys to learn what how what how is the thought process going in building this whole journey of of coming up with a model so that thought process is what will help you in in solving any kind of a model it could be linear regression it could be logistic regression it could be neural networks it could be llms anything anywhere you go but the thought process can be taken as a foundational process and can be applied okay that being said let's move forward so now I got cost function um and now so I say

0:13:25 -  3x1 + 3x2 if I if I go with this this is my cost okay now how can I reduce my cost the only way that you can reduce the cost is in in this whole picture if you see X1 X2 that is there it is fixed Y is given YP is is derived by this equation so YP can change so when YP changes YP minus y that is difference will change and if difference changes the cost will change so the only variable that we see is to change YP right because remaining all are fixed so how do you change YP the only way to change YP is to change this equation how do you change that equation the only way to change that equation is whatever is the variables that there is 3 three that is W1 W2 let's say we put it in bracket W1 into x1+ W2 into X2 so you can change W1 W2 so how do you change W1 W2 that's a good question so now how do you change W1 W2 and that should change basing on what cost function correct so I mean not on basing on that but the objective of changing W1 W2 is to reduce the cost function correct the so you change W1 W2 the cost function reduces you change it again reduces you change it again maybe it is increasing so the objective is to decrease the cost function as much as possible so so the cost function let's say we put cost function into we put all possible cost function like we do random of W1 W2 multiple times and uh maybe in a Range like W1 W2 in a range of 0 to 100 huge right and in 0 to 100 I'll calculate the YP I'll calculate the cost for all combinations of W1 W2 so means 0 comma 100 values range of W1 0a 100 value of range of W2 these two combination will be 100 into 100 right 0 0 0 1 all that combination right so for all that 100 into 100 combinations let's say I'll I'll calculate cost now I'll put all that cost details with respect to W1 W2 this is W1 this is w 2

0:15:59 -  and this is cost so if W1 is 0 W1 is 1 or W1 is 5 then 0a 5 what is the cost so I'll put it here so if you can understand in three dimension W1 0 W2 5 and for that what is the cost corresponding cost right so we can put the cost like that if you start putting the cost of all the cost all possible costs so I can see all possible costs now if I look at all possible costs all I need to f figure out is within this what is the minimum cost right like if you assume it's call the costs are in one column all I need to do is min of the cost and it will give me some value and that for that Min of the cost on this I'll see what is the corresponding W1 W2 correct so and I think that solves the problem agree uh it all sounds good but again we should always focus on what is the variables right in the whole machine Learning Journey in the all algorithms and stuff what are the variables W1 W2 is a variable okay then you said there is cost which tells you an indicator saying how how good your model is right then you said okay then how do you calculate what is the minimum cost then you said okay minimum you take a range calculate minimum cost and see whichever is the minimum Min of this cost then take corresponding W1 W2 that's ni nice but what is the Assumption again we are taking a range and within the range it's a variable right I've taken 0 to 100 just because the numbers are good I'm just telling you 0 to 100 what if the um the range is actually 0 to th000 right because it all depends on what is x1's value what is the range of it and all that stuff right so there are multiple factors basing on which the W1 W2 line will change because because if 0 to 100 W1 X1 will actually be like if there is 100 here there is 100 here um your line will be in between that right so your line will be going like that something like that right so but what if the points are so distributed X X1 X2 points are so distributed in space so that this line will not be even close to the other points right so you want to be closer your line you want it to be as much as possible either the line is

0:18:32 -  like this or like this or whatever line is the line is should be closer to the point so that the cost is is low otherwise if you draw a line here and if your points are the distance between the X and this line is higher so obviously cost will be higher because YP is here and your y's are here Yus YP is higher so as the line grows CL closer the Y minus YP is reduced if it is reduced loss is reduced cost is reduced that's our objective right so we need to move it closer correct so and and to do that you don't know what's the range 0 to how much okay let's say I say okay then why not just take a big number right like 0 to 100,000 yeah fair I mean I if if you you I'm always thinking in this direction but there's also here right so actually it should be minus 100,000 to 100,000 so that's around 200,000 even that might not be accurate because 100,000 sounds big for us but it could be above that also right anything is possible in real world data it could scale to millions and billions of records and you don't know how it should be uh how it can vary and all that so you can't you can't guess it that's the big problem with machine learning right because you can't guess an answer you're using machine learning to help you predict it right so you can't assume it so even even if you take minus 100,000 to 100,000 we are talking about 200,000 values and we we are talking about combinations if you look at it W1 W2 200,000 combinations that is 200,000 into 200,000 combinations is what uh we are talking about that's that's a huge number right 200,000 itself is 10 power 5 and and we are saying 10 power 5 into 10^ 5 4 into 10 power 10 power 10 combination is what we looking at now maybe people don't know what to do next they would have done this but what happens when they do 4 into 10 power 10 combinations of W1 w to cost function calculation using this particular thing how much time it would it take how much

0:21:5 -  compute would it take it's a huge exercise and then for for 4 into 10 power 10 ex you 10 power 10 numbers you need to find out a minimum and then you'll get W1 W2 and then you even still you are not you don't know if it's accurate agree so I don't think this can give you best of your resumption solution that is assumption isus 100,000 to 100,000 is is the range in which your W1 W2 optimal value will be there but we don't know where the optimal value is so what do we do there's no there's no right way or wrong way right so the final step to find out final step we which we don't know the first thing that we need to know is how do you know what's your first step correct so in this whole space in this whole Space of W1 W2 and cost function and stuff let's say within W1 W2 you are at certain point W1 W2 combination W1 as some a w b a is here right from there what is your first step how do you take your first step your first step is is should be relevant to your objective that is reducing the cost function so I would take a step in a direction in which my cost function will will get reduced okay so uh how do you reduce your cost fun W and W2 in order to get lower cost function right that is what is the objective everybody's with me till here if you if you have missed the point on what I'm trying to say I would seriously suggest it's okay just go back and listen to what I have explained and if there is something you don't understand please understand um but the objective is change W1 W2 values to reduce the cost correct so if you are in a space where W1 W2 is a comma B like for as it is 3 comma 3 here if you space a comma B then how do you um uh how do you pick up your next value right so that um it reduces the cost and that's your

0:23:36 -  first step that's your preference First Step because you a comma B is is here in space if you can go this way this way this way you can go a number of ways all circular All Points which are at certain distance from a comma are possibly your next steps right next baby step when I say baby step I'm talking about small step okay instead of doing when you if you take a bigger step that means from a comma b as Center if you look at your radius and if you take bigger steps the possibility of steps is is more so I'm saying let's say reduce the size of the step and then if you take I want to just move by one point right then what are the all the posses possible ways of a comma B there will be multiple possible ways right now that is easy right so um how many will be there a comma B then in a now now you keep a on the a comma B if you look at it a comma B then a comma B will have a minus 1 comma B A + 1 comma B and uh a comma B minus1 and you'll have a comma b + 1 so these are all the points that are that are possibly um there is it correct no so when I say it's it's plus one based it could also be the remaining sides right like I I looked at these sides but there is also diagonal Corners right all four diagonal Corners will not also be considered so all these points needs to be looked at and we calculate for all those points and take that one step saying whichever cost is is reducing further for example let's assume that a comma B minus one when a comma B is here a Comm B minus one is actually lesser cost compared to all the remaining eight of them then what we do we move there and then again do exercise pick up all the points again we move here and then we so what we do we can take those baby steps basing on what is the right thing but I simplified saying I'll take only plus one right it could be plus two it could be+ three but if you if you go on plus one and then if you keep reducing it takes more time and um it need not necessarily be + one

0:26:41 -  always right it could also be it could also be plus 0.5 we don't know right which is lower okay so what is this is not taking us to an optimal solution what is what what can we do so if there is a way uh we can figure out how W1 W2 can be reduced in in in a way that the cost is reduced that's our objective how can we do it so again I will instead of um objective is very clear but um how can we do it right okay what people observed when they did experiments as I said they did experiments saying this okay take 0 to 100 100 into 100 draw a graph kind of stuff so they did draw a graph and um they they keep a point so let me use um let me use some image from online just looking for better image that's all yeah this looks good for me so if you get look at this so what what is here is in a in a plane what they did they have picked up uh okay this image is the most famous one and they picked up this they are using TAA 0 Theta 1 is nothing but W1 W2 for a given W1 W2 J of W1 W2 is their representation of cost function so they the same thing that we did like this is Theta 0 this is Theta 1 and this is J of theta 0 comma data 1 and they put it into a graph okay a certain range of values when they put certain range of values they started here so we are here with a random Theta 0 Theta 1 here okay so what they did they picked up a baby step which actually reduces the cost if you see here it is visually it is clear saying because he what he did this guy um smartly within the distribution he color coded it basing on the value ranges that is these are on the higher side Reds are highest cost yellow is like average middle cost and lower he goes he was actually using color blue and the least is he's actually getting

0:29:19 -  to the more bluish color is the most least the higher red is more higher so that's color coded the value ranges of how the cost is going so obviously the objective is to move from red to the to the blue points right and then there are different possibilities on where you go but the objectives of thing is um on how to go to the least possible point that is here okay so what happens from here you take baby steps here here here here here here so you you take baby steps at every Point correct so looking at this specific point if you if you zoom it you have you have possible the within the cost function if you look at it you have something like this curve right and then you are coming you're coming down what do what does coming down mean you're descending right you're descending from there so that's okay you're descending down and then you're descending down the cost to reach the optimal values for W1 W2 so that your algorithm works in the best way good how do you descend from that particular point so for that what he says we'll use another image to show how we can derive a descent so what happens here at a certain point if if I mean this the cost function which is in the image you you have seen in the previous image you have seen U the not this one I'm sorry yeah in the previous image you looked at this red pce part of it right let's say let's say we take that red piece part alone and we we represent it like this right the reverse of it I mean that's how the image is like you should you can look at it like this red P where J of data is going like this and you are here somewhere so that's what he means when he keeps a point there here that's what he means that you are here so from here whenever there you want to go in this direction the they bought it to 2D but it is 3D so from here you can go here you can go here you can go up all directions are possible but what you want is go somewhere below either like this like this like this anywhere is fine so how do you determine that

0:32:23 -  instead of the two ways one you verify as I said do a small give a small Gap to it and uh in that Gap like plus 0.1 for everything and then um see how the cost is varying and then you can pick the baby step or this is somewhere the concept of differentiation can help to tell us what is the um direction in which we can go in which the value will actually reduce fine so um I can simply say that and then tell you okay let's do differentiation there and stuff but um I feel why why leave that concept alone okay I I understand few of few of you guys and even me um even though I'm confident to say I'm good in math but the concept of concepts of math no one knows all the concepts properly somebody's very good with algebra somebody is very good with equations and so whereas somebody is not that good with geometry and so there there's nothing called somebody good in math where he understands everything he might understand one concept but so let's assume that we don't know what differentiation is okay let's let's look at a little bit let's spend a little time and and then see what is differentiation how differentiation is done in gradient descent and U so that it it helps in uh it helps in reducing the value okay okay uh because that's this is the very important concept on achieving the final model right in optimal let's ask chat gp2 to explain us okay um yeah we can use this it's okay type here okay this is nice instead of hiding it I'll just put it somewhere here explain um gradient descent derivation on U okay no not sure itce let's see I can't proide images I know differentiation in mathematical concept used to compute the rate at which a function changes with respect to its inputs to calculate the derivative of a function which represents the slope of the function at a particular point in

0:36:37 -  context of outut okay he he something okay this guy doesn't explain with a visual examples I'll again fall back to this is good I think this is what I at while ago this guy got in he doesn't explain what differentiations or maybe I should ask the question mhm let see no doesn't explain it so um okay because of the time Factor again I I'll tell you guys um my understanding of differentiation but we can you guys should should get into the details to understand it better but what happens how differentiation Works let's say you take a slope like this right okay the possib you could be anywhere here right so at a given point what differentiation does is it it it assumes it it takes a point like this and with respect to your this line that you have it draws a straight line which is actually perpendicular to that particular point that is there in this curve okay how does it do it it assumes it is assumes for that specific point it assumes that the point it it varies a little bit How does it go and basing on that it it it creates a perpendicular line when I say why am I saying perpendicular line that's what is is confusing so what is perpendicular if you if you take a specific line perpendicular line is like this right so it's not perpendicular if it's perpendicular it'll go it'll go differently um I'm doing a bad explanation of differentiation but given a curve it will actually give you the slope of the particular curve right because the curve can be in any form right it could be like this so if if it is like this if it is like this you know this is the slope right but usually not like that so slope is like this the slope is like this the slope is like this the slope can vary basing on which point of this curve that you could you could get into so it would differentiation would give you a slope of that line so if if you get slope of a specific line right so what does it tell