# Day 39 Study Time Gen AI

**Time Interval:** 00:00 - 37:25  
**Summary:**
- **üîç Session Overview**: The session discusses the recent break taken from studying, emphasizing the importance of catching up on topics covered in previous sessions.
- **üß† Learning Focus**: The instructor expresses a commitment to deeply understanding generative AI, stating that even if it takes time, the priority is on acquiring solid foundational knowledge of generative language models (LM).
- **üìö Generative AI Explained**: The session explains how generative AI can answer questions, rewrite contextually based on different scenarios, and leverage knowledge from a vast array of texts to provide answers.
- **üîß Practical Exploration**: The instructor outlines plans to improve and optimize generative AI environments and to explore NLP and LLMs in detail, setting a foundation for future applications such as building agents and environment setups.
- **üìä Reviewing Progress**: Acknowledging shortcomings in tracking progress through metrics, the instructor reflects on what has been studied thus far and emphasizes the need for a more structured approach moving forward.
- **üìù Future Directions**: The session concludes with a roadmap for upcoming topics, including embedding techniques, Transformer architecture, LLM specifics, and various frameworks, while encouraging a thorough understanding of the material before moving on.

# Transcript 


0:2:48 -  hey hi um yeah there's a break for a while um yeah how many days more than 10 days I guess very bad anyways we are back so no issues only thing is just because we took a break in between um we'll just catch up and see um did we come so unfortunately from last I guess five days or so we are still in embedding only um I I can speed it up and then make it faster but I don't want to do that because uh uh edding is pretty important usually when we study we skip things uh in between because of time constraint or something like that good part is I don't have the time constraint so um so I should um uh even if it takes time even if it take months of is okay but I should uh focus on learning things properly so that U the foundational knowledge about uh the generative a LM and stuff is very clear um the the main objective um is to understand the um put it in a simple way um How is generative AI uh able to answer questions um uh in a proper language and it is able to rewrite it basing on different scenarios as in ages and something like that so uh so it's able to so it's ability to understand the way I look at it is generate way is able to look read um that's a set of books and it's is able to understand all the books and it is able to answer questions basing on the all language are the text that is available in all those books it is able to answer answer questions so uh so um how is it able to do uh to the detail and um um so and and and then we'll get into the other sides of the story that is how can we improve it how can we make it better um how can we set up environments

0:8:9 -  where we can run llm models how can we build agents that is where we'll head to it but before we go to that um more like an applied uh data science kind of stuff we want to understand the foundational knowledge and basics of NLP llm and stuff so that we'll be having a stronger knowledge in generative AI so okay with that being said let's let's get to the current state where we are what we have studied and stuff bad part we didn't maintain any metric on uh uh uh we didn't keep a list on which all topics we are covering and stuff so that they have check box kind of stuff we would we have said these are all completed this is still ping kind of stuff but it's okay I can recollect from embedding perspective we clearly um [Music] [Applause] [Music] just give me one second [Music] guys sorry about that oh my [Music] okay let's share the screen go to chat GP get started let's find out where we have okay here we [Music] are yeah here is where we had some planning yeah cool [Music] very good more organized whatever topics we are covering if it is covered in some other course we can also take that course because this is going little dra because I'm all over the place I'm going to one I'm going deep into it few topics going deep into it let's see that's us for today we'll focus on that so for [Music] NLP [Music] NLP for course one welcome to n language person first introduction to computing

0:34:22 -  [Music] langu for s e for for [Music] this this for see that's I'm going do this [Music] spe what s e for h s for for sh [Music] on for I doubted that can demonstr person it doesn't make sense without doing that how is it understanding questions and okay let's [Music] okay this might be true more [Music] efficienc for come to be [Music] [Music] answer for been I'm been expecting for [Music] for that for for [Music] [Music] this all [Music] the broad on yeah see specific models within NLP designed to handle large scale text processing and generate as e for for [Music] o for [Music] okay the sentimental analysis anal can do better than is what he's saying it's interesting it's okay [Music] MH this is nice I think this is where we need to learn NLP bring it to llm merge them together for example they they are already doing like um if um they're taking text image and uh now liation this this limitation that is being called out as text image and video processing capabilities Laing inm it is I think they're doing an simple technique there where they're using models from NLP to process these particular inputs and then give it as

0:38:53 -  input and then extrac data kind of stuff this is nice few of them are being addressed I'm sure sentiment analysis is something I need to get into the details where analy and outperform LM is something I need to do rule based information extraction is also possible because re LM in recent times with respect to agents um it's also is kind of an asemble technique is able to do all the I think also it can do do properly but the boundary line in between Al and is something we need to see but uh if we segregate alms alone without having these addition capabilities added as in because alms are trained on huge amount of text so they can take uh input as text and output as text considering that fact uh I agree with uh the option saying um if it is is input which is not text and then output expectation not text then it would not understand that's that's agreeable um reminding things like um sentiment based analysis rule based uh task based part task pass and spe and all that stuff um that's where the agents are kicking in at are using multiple things reasoning and task specific and stuff I extraction [Music] specific e [Music] that's what he's saying so this Frameworks [Music] that's super plans [Music] I [Music] oh it's using 40 is [Music] it [Music] nice this is what is being after some time the tokens will expire and not for