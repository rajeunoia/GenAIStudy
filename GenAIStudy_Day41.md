# Day 41 Study Time Gen AI

**Time Interval:** 00:00 - 32:23  
**Summary**  
- **üîç Overview**: The session introduces the **LangChain framework** for building AI agents, focusing on the concept of chaining actions with an emphasis on deep planning and using external tools.
- **ü§ñ AI Agent Functionality**: It discusses how AI models can respond intelligently by generating actions based on reasoning and incorporating additional capabilities to enhance performance.
- **üõ† Tools and Incremental Capabilities**: The instructor outlines the importance of using the right tools at the right times, integrating them incrementally into the AI model's workflow to augment its intelligence.
- **üå¶ Dynamic Information Retrieval**: An example is given on how to retrieve real-time information like weather data using external APIs to overcome the limitations of AI models, which may not have access to dynamic information.
- **üîó Chaining Actions**: The concept of chaining actions is examined, detailing how the flow of tasks is organized and executed, allowing for more dynamic interaction between models and external tools.
- **üìä LangChain Components**: Key components of LangChain, such as prompts and tools, are introduced, along with best practices for using them effectively in building agents.
- **üöÄ Next Steps**: The session concludes by promising further exploration of LangChain's components and practical coding examples in subsequent lessons.

# Transcript 


0:2:38 -  hey um hi guys so we will um we'll continue our course on the a agents and langra um uh but in deep planning just going my Lang chain and Lang chain is the framework for building a a flow flow flow based uh um if if low based uh steps not flow based what you can actually [Music] say so um I I'll quick let's make it quick because there's no time um the once you call ANM model it gives you a response right so the response is smart enough that it can actually um give you reasoning also so people have got a thought saying um what if the uh if the thoughts are converted to actions right so if and if if it has additional capability how does how can we give additional capability to an model which is already smart so for this thinking the thought process is is uh giving it more tools so uh but these tools needs to be used the right tool should be used the right time kind of stuff and at the same time uh it should be incremental to the model right so you um ask the model it gives it an output and then we use certain tool fix additional information or or get some specific task done and then you go back to Al and say Okay um this is my prompt this is the uh action you we thought you should do and this is what I have done so this is the output kind of stuff so then we we give that output of that particular action to The Prompt again and then say okay this is what has happen and the llm is smart enough that it can actually say what is the next um logical step kind of stuff say what should be the next action kind of then you perform that action so it's l chain is nothing but we are chaining whatever actions that needs to be that needs to be done we are chaining them together in steps and we are also using external tools which are required for example initially um but even GPT 4 o is

0:5:47 -  able to do but GPT 3 if you see the limitation is it can't do a dynamic search and fetch the results from outside and then use them so even now um 40 is limited search kind of stuff it is not a global search um as far as I know so uh what they we used to do is in Lang chain um you call model it gives you answer as for what it knows it doesn't understand what it doesn't know so for for example if you want to know what's the what's the weather today in specific place and basing on that you want to make some travel planning and all stuff so but the llm model doesn't know what is the weather today it's a dynamic number right so what we could do is so we'll create an action there to find out present weather in some place and then we will use a tool that is like um calling an API something like that and then we fix the weather using that API and then basing on that we will um take the next steps now so getting the current weather in a specific place or current the weather forecast of specific day in a specific place um let's assume that that's the uh so let's assume that that's the that's one of the inputs that is required for our agent to work but we llm doesn't have that capability so we complement that uh gaps using um using this additional tools and Stu so that's what is it is briefly but um let's understand more about it the further lesson okay let's share and Screen this one [Music] to share audio share a tab instead oh okay Chrome tabs beautiful so now I'm sharing a specific tag is very good so Oops why did I pick up a and let D okay let's [Music] reshare share this test yes so M here nice so we'll play this welcome to AI agents in land draft builds in partnership with L chain and taught by Harrison Chase let's quickly recap on this in the last lesson you built an agent from scratch now let's implement the agent

0:8:21 -  using the Ling graph and along the way introduce some of its components and features all right let's get coding all right so let's break down what exactly we did in the last lesson we had this user message that came in we then had the system prompt and this was this very long one we then called an llm with that this outputed something like what's right there a thought and an action based on that we then made a decision we would either return or we would call a tool and we put this all in a big loop this query function and we had these two tools that we would call calculate an average dog weight and if we call the tool we would get back an observation and then would loop back in to the prompt and would put that observation as a new message so let's break this down into Lang chain components first let's talk about prompts so prompt templates allow reusable prompts and what this basically means is that we can create something like this right here a little string some formatted variables that we can replace and so those formatted variables can come from user content so we can have this prompt template that we format in different ways depending on the user content if you want to see a bunch of examples of these prompt templates you can actually see them in the Lang chain Hub so here is one that's very similar oops sorry sorry sorry in the last lesson so here is one that's very similar to the agent prompt that we just used so you can see here it says answer the following questions as best you can you have access to the following tools and here we don't hardcode the tools themselves but we have this little variable and same with tool names down here and then we have the input here and this is the user question and then the agent scratch pad and these are all the actions it takes and the observations if you want to see more prompts you can go to the hub here and you can see a bunch of prompts that people in the community have contributed the next component in L chain that we have is tools so here's a tavill tool and this is the search that we will be using from here on out you can see that we import it from the Lang chain Community package which contains hundreds of other tools maybe the biggest part of this application the most code that we wrote was this function that would Loop and that's represented by all these arrows

0:10:52 -  here and that's one way to think about lingraph lingraph helps you describe and orchestrate that control flow specifically it allows you to create cyclic graphs which is exactly what we have here it also comes with built-in persistence and this is really nice for having multiple conversations at the same time or remembering previous iterations and actions this persistence also enables really cool human in the loop features if you look at these diagrams here and these are all diagrams of Agents from academic papers these are all all represented as graphs and that realization was what led us to create L graph an extension of L chain specifically aimed at agent and multi-agent flows crucially it allows for really controlled flows so in these diagrams there's really specific arrows leading from one box or state to the next we've seen that this control ability is crucial for creating agents that can perform well three of the Core Concepts of Lang graph are nodes edges and conditional edges nodes are agents or functions edges connect these nodes and then conditional edges are used when you need to make decisions about which node you should go to next so let's take a look at an example of the L graph you can create that is equivalent to the function that we wrote in the lesson before we can have an agent node this is the LM we can then have a conditional Edge which takes the result of that llm call and decides what to do next one of those edges can be an action Edge which calls a function node and that automatically Loops back to the agent node there's an entry point which is where you start and then there's the end node which is the other action available to take after the agent one of the most important things to understand when working with L graph is the state that is tracked over time this is often called the agent State this is accessible at all parts of the graph at each node in each Edge it is local to the graph and it can be stored in persistence layer meaning can resume with that state at any point in time later on looking at two examples we first have a simple state where we just have this list of

0:13:24 -  messages taking a closer look we can see that this message variable is a sequence of Base message base message is a lang chain type it's annotated with operator. add this means that when the state is updated with new messages it doesn't override the existing messages but rather it adds them to that state let's take a look at a more complex State here we have input chat history agent outcome and intermediate steps they all have their own different type three of them are not annotated It Anyway this means that when a new update is pushed to that variable it overrides the existing value there however intermediate steps is annotated it's annotated with operator. ADD which means that when a new update is pushed there it adds to it this makes sense because intermediate steps is what is tracked as the agent action and agent observation throughout the graph as it executes and so we want to continuously add to that as more and more actions are taken getting really specific about the previous agent that we created and how that would map to a l graph object we can see that we will have one node we'll call this call open Ai and this will call the llm we'll then have a conditional Edge which will check for the existence of an action to take and so we'll call this exists action and then we'll have another node which actually executes that action we'll call that take action and the state that will track is pretty simple it's just this list of messages to which we add over time with that highle overview let's dive into the code let's first load in any environment variables that we're going to need to use this is our open AI API key we're now going to import a bunch of things that we need to create these tools agent State and the L graph itself first let's import State graph and this end node from L graph we'll see how use those later on these typing Imports and operator are used to construct the agent State we then have all these different message types these are Lang chain message types that we'll use to represent the human and Ai and system messages from Lang chain openai we're going to import chat open aai this is a l chain wrapper around the open aai API this exposes a standard interface for all language models meaning that even

0:15:56 -  though we're going to use chat open AI for this lesson we can actually switch it out for any of the language model providers that Lang chain supports without having to change any other lines of code finally we're going to import to vill the search engine that we're going to start using as the tool on this example let's first take a look at the tool we'll create the tool by initializing tavil search results with Max results equals 2 this means that we'll only get back two responses from the search API see that it's of this type and it's got a specific name t vilore search results _ Json this is the name that the language model we use to call this tool let's now create the agent State this is exactly what was in the presentation it's just an annotated list of messages that we will add to over time let's now create our agent as discussed we're going to need three functions we're going to need one function to call open AI one function to check whether there's an action present and another function to take that action these will all be different methods on this agent class so let's create those first and we can then see how they interact with each other let's now create the agent class we're going to want this agent to be parameterized by three different things a model to use the tools to call and the system message as before let's save the system message message as an attribute we're now going to start creating the graph first let's initialize State graph with the agent [Music] state right now this graph is pretty it doesn't have any nodes or edges attached to it we know that we're going to want to create those three functions before and use them two as nodes and one as edges so let's sketch it out and then we'll Implement those functions as methods on the class so first we know that we're going to want to create a node called llm which will execute the llm and we can do that by doing graph add node llm and then we're going to need to come back here and we're going to need to pass in the function that we want to represent this node We'll add another node the action node we'll do the same thing here now we're going to add that conditional Edge this goes after the llm

0:18:47 -  is called it checks whether there's an action present if there is then it goes to the action node if there isn't then it goes to the end node and it finishes so let's add this again we'll have to add the specific functions later on the first argument we pass in is the node where the edge starts this is from llm the second argument we pass in is the function that'll determine where to go after that we're going to implement this later on so we'll leave this blank the third and final argument that we're going to pass in is a dictionary representing how to map the response of the function to the next node to go to so if the function returns true then we're going to go to the action node if it returns false then we're going to go to the end node we're now going to add a regular Edge this is going to go from the action node to the LM node so we can do this by calling add edge the first argument is the start of the edge the second argument is the end of the edge we're then going to set an entry point for the graph this is at the llm node with that done we can compile the graph graph. compile is just what we need to call after we've Dawn all the setups and we'll turn it into a lang chain runnable a lang chain runnable exposes the standard interface for calling and invoking the graph we'll we'll see more about that later on we'll save this as an attribute on the class we'll also save the tools and the model that we passed in for the tools we'll create a dictionary mapping the name of the tool to the tool itself for the model we'll actually call buy tools on the model passing in the list of tools that we passed into the agent what this is doing is this is letting the model know that it has these tools available to call all right so we've created this graph but we still need to create three things we need to create the function representing the llm node we need to create another function representing the action node and we need to create a third function representing this conditional Edge We'll add all of these as methods on this agent class for the llm node we're just going to create a function called call open AI it's going to take in this state this agent State all of the nodes and the

0:21:28 -  edges will take this in what we'll do is we'll get the list of messages from this state we'll then add in this system message and then call the model we'll then return this dictionary with a list of messages but there's only one message in it it's the message that's returned from the model again remember because we had annotated the messages attribute on the agent state with the operator. add this isn't overwriting this it's adding to that state we can then go back to the graph. add node and change that pass in this method let's now do the same for the action node the the action node will also take in this agent State we'll get the last message from the list of messages we know that if we've got into this state the language model must have wanted to call some tools that means that there will be this tool calls attribute present on the last message in the agent State crucially this can actually be a list of tool calls so a lot of the more modern models support parallel tool or parallel function calling what we can now do is we can Loop over these tool calls we can find the relevant tool by looking up tool name in in the dictionary of tools that we created we can then call invoke on it passing in the arguments that we have from this tool call we can then append this as a tool message to this results list and then we're returning this messages mapping to this results thing again this is just the new messages that we need to add what's happening under the hood is that Ling graph is adding that to the state in between iterations we can go into the me we can see first it calls to villy with the query a little bit different from parallel function calling it's not happening in parallel it's happening sequentially and the reason it's happening sequentially is it actually needs the result of the first query in order to make the second query at all with this we've seen how we can take that raw llm and raw python example with some some fake tools and turn it into a real agent that can answer complex questions under the hood it's using the tavil search API in the next lesson we'll learn a lot more about that a frequently used to in agent is search this lesson is going to dive into how agentic search is different from standard search and how to use it let's try it

0:23:58 -  up all right so before diving into what an tic search does let's understand how an agent might use it in a zero shot learning an agent would receive a prompt and will produce an answer based on its static weights of the model as powerful as it proven to be there are many limitations to this process first the data around us is dynamic so we couldn't for instance ask about the scores from the game last night secondly in many use cases we would want to know the sources of the information provided in the result this can reduce hallucinations and smooth the friction of this human computer interaction looking at the slide we can see the prompt is received by the agent which then decides to call the Search tool then the information found is returned to the agent now let me show you what happens inside this is an example of a very basic Search tool implementation let's go over it step by step if the agent decides it will send a query to the Search tool the first step would work on understanding the question and divide it to sub questions needed this is an important step because it can handle complex queries then for each subquery the search will have to find the best source choosing from multiple Integrations for example if an agent would ask how is the weather in San Francisco The Search tool should use a weather API for best result result the job doesn't end with finding the correct Source the Search tool would then have to extract only the relevant information to the sub quare a basic implementation of this can be achieved through a process of chunking the source and run a quick Vector search to retrieve the top K funs after retrieving the data from its source the Search tool would then score the results and filter out the less relevant information okay so let's test it out okay so first let's import some libraries and do the initial connection to the Search tool here we loaded tavil API key from the environment variable and then we create the tavil client which we imported from the tavil library all right so after creating the initial connection Let's test it out here I'm going to run a search asking about nvidia's new black hole GPU and let's see what's the answer all right so as you can considers a pretty simple answer but very

0:26:40 -  accurate okay so let's do a simple example to see the difference between a regular Search tool and an tic Search tool I'm going to create a simple query about the weather in a certain location feel free to change the location to your location I'm going to do it with San Francisco so the query is what is the current weather in Francisco should I travel there today now let's try to attempt it with regular search here I'm going to import the dcta go search I'll try to run a regular search and get the links the links that might lead me to the answer okay so as you can see we did get the results but it's not what the agent need now we're going to have to get some answers from these results let's do that okay so now we're going to create a function that going to scrape the data from the first URL we're going to use beautiful soup to extract the HTML as you can see that's a beautiful output and if you want you can keep scrolling down but let's try to clear it up okay to clear it out I'm going to use some parsing I'm going to extract the headers and some content I'm going to strip it down and use join to get the text as you can see the output is much much better but still not concise enough okay after seeing this let's try to run it using the agentic Search tool we're going to do the same query and col to get us the results as you can see we got a simple Json with a lot of information about the weather in San Francisco let's clear it out we can see a form the Json okay now we par the and highlight the Json just so we can see it clearly as you can see this is not the answer I would want to see as a human but this is the exact answer an agent would want a structure data okay I'm going to load the sample from Google search so you can see the difference here I get exactly what I want as a nice image showing me the temperature the humidity the wind but not unnecessary data that's exactly the difference between what a human need and what an agent need okay that was an introduction to agentic search in the

0:36:59 -  next lesson Harrison will discuss persistence and streaming so this travel is cod is this all is is explaining how it is done without using Trav Trav it is going to be very press here you should search with C query quer I didn't he do that no the current ACC is temperature 23. [Music] cast 7% okay let also has going to rain comp let's see how it work did you do all that all of that I doubt it that's interesting no so it has broken down all the three places and it have sented there let see some where it's raining um f okay let's try h anotherus [Music] however it is recommended to check for time interested for Hamilton Texas the provided Source oh come on man okay let's go to Florida okay go [Music] back loc heing PR heavy rain falling [Music] so there is 30% chance of sh TA today oh if I say Frisco Taxas it's being more [Music] clear see how can it be man there's something wrong [Music] cled [Music] this is complex it doesn't give the places in between okay that's okay fine for [Music] system [Music] it got one place but maybe it would get this is yeah nice it's working man when building agents they're often working on longer running tasks for these types of tasks there are two really important Concepts persistence and streaming persistence lets you keep around the state of an agent at a particular point in time this

0:39:37 -  can let you go back to that state and resume in that state in future interactions this is really important for long running applications likewise with streaming you can emit a list of signals of what's going on at that exact moment so for long running applications you know exactly what the agent is doing let's see these Concepts in action so to get started let's create our agent at as we did before we'll load in the appropriate environment variables we'll make the necessary Imports we'll create our tavil Search tool again we'll create our agent State and finally we'll create our agent again now we're going to add in persistence in order to deal with persistence we've added the concept of a checkpoint into L graph a checkpoint basically checkpoints the state after and between every node to add in persistence for this agent what we'll do is we'll use a SQL light saver so this is a really simple check pointer that we've added that uses SQL light a built-in database under the hood and we'll just use the inmemory database so if we refresh this notebook it'll disappear but but you can easily connect this to an external database or we also have other checkpoints that use redis and postgress and other more persistent databases like that once we initialize this checkpoint the way that we can use it is we're going to pass it in to graph. compile so in order to make this easy let's add another parameter to agent that is check pointer and then we're just going to pass check pointer equals check pointer right here and we've modified our agent this is all we're going to need to do we can now create our agent and we're going to pass in checkpoint equals memory and remember memory is the object that we initialized above when we use our agent now we're also going to add the concept of streaming and there's two things that we might care about streaming first we might care about streaming the individual messages so this would be the AI message that determines what action to take and then the observation message that represents the result of taking that action the second thing we might care about streaming is tokens so

0:42:20 -  for each token of the llm call we might want to stream the output to begin we're just going to start by streaming only the messages we'll do the tokens later on in the lesson so we're going to create our human message what is the weather and SF this is the one we ran before we're now going to add this concept of a thread config so this will be used to keep track of different threads when building AG so this is a really simple checkpoint that we've added that uses sqlite a built-in database under the hood and we'll just use the inmemory database so if we refresh this notebook it'll disappear but you can easily connect this our human message what is the weather in SF this is the one we ran before we're now going to add this concept of a thread config so this will be used to keep track of different threads inside the persistent checkpoint this will allow us to have multiple conversations going on at the same time this is really needed for production applications where you generally have many users This Thread config is simply a dictionary with a configurable key and as part of that we have a thread ID and we can set that equal to any string here we're going to set that equal to one we're now going to call the graph not with invoke but with stream we're going to pass in the same messages dictionary and we're also going to pass in this thread config as a second parameter there we're then going to get back a stream of events these events represent updates to that state over time because we know our state only has one key the messages key we're just going to Loop through it and print that out so let's run this and see what happens we can see that we get back a stream of results first we get back an AI message this is the first result from the language model and it's telling us to call to vill next we get back a tool message this is the result of calling to vill and it has the results from the search and finally we get back a third AI message this is the final result from the llm answering our question with this stream method we get back all of these intermediate results and we have really good visibility into what exactly is going on let's now call it with another message this time we're going to say what about in La so this is continuing the same conversation that we had before

0:44:55 -  it's asking a followup question we don't say anything explicitly about the weather but based on it being a conversation we would expect it to realize that we're asking about the weather here in order to make sure that we're continuing from that same point we're passing in the same thread ID here if we run this we can see that it returns first a function call where it's looking for current weather in Los Angeles again it's knowing that we asked about weather because it has this persistence from the check pointer we can then see that it's getting back results from tavil and finally that it's responding with an AI message that says the current weather in Los Angeles is blah blah blah we can call this yet again using the same thread ID with the message which is warmer here it has access to the full history so it can accurately respond Los Angeles is currently warmer than San Francisco just to demonstrate the importance of this thread ID let's change this to be two if we run this now we can see that the language model is really confused can you please specify the two or more items you are comparing to determine which is warmer that's because it doesn't have access to any history and that's because we're using a separate thread ID so we've covered the import of persistence and we've showed how you can stream events but what about streaming tokens themselves for that we're going to want to use the aam events method that comes on all Lang chain and Lang graph objects a stream events is an asynchronous method which means that we're going to need to use an async checkpoint in order to do this we can import async sqlite saver and pass that to the agent this is very similar to before it's just swapping out a synchronous SQL lightsaber with an async SQL light saver this allows us to use async methods on the graph we'll use a new thread ID so this will start the conversation from fresh we're also going to be iterating over a different type of event these events represent updates from the underlying stream what we want to do is we want to look for events that correspond to new

0:50:5 -  tokens these kind of events are called on chat model stream when we see these events happening we want to get the content and print it out and we'll print it out with this pipe delimiter when we run this we should see it streaming real time into the screen so we can see a few things here first we can see that it called the function under the hood the reason it didn't stream out anything there is there actually was no content to stream it was just a function call but then we can see that when it did get to the final response and it is returning a final answer we stream out those tokens one at a time we can see that we've got this little funny pipe delimiter here but we could easily remove that in our production application if we wanted to so that's it for persistence and streaming pretty simple to get started with but really powerful for building production applications you're going to want your agents to be able to have multiple conversations at the same time and have a concept of memory so they can resume those conversations and you're also going to want them to be able to stream both the final tokens but also all of the messages that came before persistance is also really important for enabling human in the loop type interactions and that's exactly what we're going to cover in the next lesson for for see 5 6 7 8 only three tomorrow yeah [Music] okay let's stop uh yeah yeah let's stop sharing here do off on Trav kind of stuff so the key thing I want to say about uh this whole agent thing is also aspect especially the persistence and streaming thing that we have seen now um the a prompt there um a PR can also be given incrementally where but where in the incremental goes for example you start with certain question or something that and basing on that you you keep adding more messages to it like a chat right agents are actually more like a chat only but whereas the the answers B between the chat instead of human answering the the certain inputs are providing certain inputs or something

0:52:36 -  like that um there are tools or like Trav is one search based tool that we have explored today which will help in Catching some results from online kind of stuff right um it is coming with an API key I'm not I think that is a paid tool kind of Stu you should look up and see how it works and stuff but you get the results right so this conversation happening what happens when you are chatting with an agent is the chat actually gets persisted somewhere either you locally on your system or in the server side it gets persisted and that's how they remember what is the chat that's happening similar scenario here when you when you have this agent working on the specific prompt that you have initially given then for example it should you can also design it in a way that it it should go in a loop and then it it should consistently pull the data on from online and then record something for example [Music] um for next 1 hour uh consistently it should actually look through the weather in um 15 places and it actually should give you what is the weather pattern or we should rate all the 15 places um in a way which is having a better weather again but weather is a subjective thing but let's say where there is less rain are a comparison between the 15 can be pulled out so that's a continuous exercise that needs to happen right so this can be achieved using a normal program right we can do using normal program but what agents are ble to do is we can achieve all that what I said without writing any program so agent by just prompting it it uh understands that it needs to search for uh weather uh needs to search certain frequency and then it understands that you need to do a comparison in between them basing on certain factors and then it understands that you need to sort order it in particular ranking or something like that so this all could be be done just by giving a a text specific text with certain values and stuff so that's the beauty of L chain and agents and all that stuff so I'm pretty sure