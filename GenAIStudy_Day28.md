# Day 28 Study Time Gen AI

**Time Interval:** 00:00 - 37:25  
**Summary**  
- **üîç Overview**: This session reviews Convolutional Neural Networks (CNNs) focusing on convolution and pooling operations, explaining their roles in image processing.
- **üß© Convolution Understanding**: It describes how convolution is applied to images by using a kernel that moves across the image matrix, capturing important features by breaking down the image into smaller pixel boxes.
- **üîÑ Pooling Operations**: The instructor explains pooling functions, such as max and average pooling, highlighting how pooling reduces dimensionality while preserving essential information. It‚Äôs emphasized that pooling cannot be combined in a single neuron with convolution but occurs in separate layers.
- **üìä Handling Accuracy**: Padding is discussed as a technique to improve accuracy, particularly for images containing critical edge information that might be neglected during convolution.
- **üéØ Output Processing**: Outputs from convolutions and pooling lead into a neural network for classification tasks. The session mentions how different outputs can be flattened and processed further for object detection with activation functions for classification.
- **ü§ñ Object Detection Clarification**: The video addresses common misconceptions about using CNNs for object detection versus simple image classification, clarifying that while CNNs can label detected objects, they don't perform the object detection itself. Instead, traditional methods like OpenCV are highlighted as viable options for the detection phase, followed by CNNs for labeling.
- **üìÖ Conclusion**: The session concludes by acknowledging the insights gained about CNNs and hints at transitioning to Recurrent Neural Networks (RNNs) in future discussions.

# Transcript 


0:2:35 -  hey hi everyone so we have covered CNN um convol networks we understood how and why convolution is applied and then pooling is applied and how combination of convolution and pooling um together does a similar function as um as a single neuron what we also understood is uh a huge image um like you you remember we have seen that n byn and then we were actually moving this kernel so um we are breaking it down so the the overall U um image that is there we breaking it down inputs breaking each pixel is n byn pixels each pixel is cons input features so what we doing is um we are U uh we are breaking down the whole input into smaller boxes what how do we break it down into boxes is basing on the way the kernel moves like if you if you represent it as an N byn Matrix we we we are taking inputs as um as the Box moves and moving that kernel across a Kel or filter across the image um uh and the steps are called strides and moving it across we we we capture the inputs and the input features are actually fed into um to the network and um if you if you feel that there is um there is accuracy problem of uh especially if the image has images have some important data in the edges then we actually go for padding uh so that the edges also have are also considered significantly as the internal pixels [Music] so um so overall if you look at it uh this each kernel has certain weights like let's say F into F Matrix then it is W1 W2 W3 W4 and those weights and uh this image that is there uh that is there that is this is split into

0:5:53 -  smaller parts like small small small spot Parts these small parts were fed into this particular um each input is given to one neuron and each neuron the weights are equalent to the kernel filter weights and the activation function is pooling the pooling has Max and average so broken on inputs are given to individual neurons for one kernel there will be X number of neurons as for how many parts you make the inputs into and those neurons will will do a first function is is W1 like matrix multiplication kind of stuff between the filter weights and the input data that is given W1 X1 plus W2 X2 plus W3 X3 um and then we have activation function is either average or Max off um wait one second one one second pooling uh this can't be the my understanding is wrong because I'll carry this same understanding the pooling is not applied on single input and single kernel I can't bind pooling to the convolution layer individual layer at least the pooling is applied on um what happens is as convolution is done pooling is similar to convolution instead of multiplying with certain parameters what we do is we again the output of convolution we broke it down into smaller parts and those part will be given to another function either average or maximum and that will give certain output so pulling helps in scaling down the image whereas convolution helps identifying the patterns these two can't be combined into a single neuron these actually are two different layers correct my understanding of putting it into neuron where activation function is uh the pooling and calculations is this is wrong because in between I mean if the inputs are same for both of them then we can put them into one neuron but the inputs are not the same right output of this particular kernel let's say we call them a11 a12

0:9:1 -  a13 A14 a15 a16 in this again the pulling will take sub parts of it similar to basing on its it also has a filter kind of stuff which doesn't have parameters so but it mov those filters and say a11 a12 A14 a15 like that like 2 by two let's say filter is 2 by the is 2x two for a PO pooling is 2x two then it takes 2x2 and it does apply a function on top of it Max of so um these both can't be these both can't be connected to each other the both should actually be considered as two different layers only thing is uh yeah that's it and pooling can be applied across all kernels and uh but output one at a time yeah so convolution pulling for one kernel convolution pulling for one kernel convolution pulling for one all of them are separate um if we use three kernels then we get U um three Kels will get three outputs after pulling and three outputs will be flattened and then given to a a Ann forward neural network and then that will actually have some kind of a sigmoid or or soft Max function for either class binary classification or for multiclass classification and they can give certain output like um like an object detection within an image like all bikes human three things we want to classif then there can be a soft Max function and uh that can actually classify saying okay these are cars these are all I mean there is a car at least there is a bike and there is a human that's some output that it can give the same time it can also give us saying where that particular uh the object detection it can also say where that

0:18:38 -  particular um object is for example it has detected a car the CNN can say that there is a car basing on what we have learned uh how do we say in which position because after pulling and stuff we are kind of losing on the actual image coordinates and all that because you are kind of encoding it the actual image n byn into something smaller using this uh convolution and pulling concept so now once the output comes in traversing back to say this is the part which influenced and uh because of this part we are saying is a car that can't be I think that can't be set by C then so in that case then we need to figure out how do we um do that's a good question to ask let's ask chbt can we do object detection with CNN foring they [Music] designed training evalation deployment nothing okay the bounding box how does CNN no the [Music] [Music] bound for is he'll repeat the same story again is training can [Music] perform or R CNN region Bas for L the how does this this happens the question cover objects in minimum of regions [Music] possible to call on object the propos in to have work is to [Music] now EX outline of image [Applause] fing do a matter [Music] m [Music] what so there would be some pre-processing done on the

0:32:2 -  image where we segregate the image into smaller parts and the smaller parts are network everything together one p kind of multiple people [Music] are for right the I'll [Music] pick the [Music] for H caset [Music] Al [Music] and how toly [Music] [Music] this [Music] okay what is [Music] C [Music] m what f learnable counter put to counters when we join all points of the boundaries of an object we get a counter specific counter to the boundary Piel and density offensive makes it really easy to find so it depends on the boundaries and stuff it is detecting what is the like counter detection chain approx simple and same detail in the examples below the counters of simple objects okay into GR scale format okay he didn't explain on give methods okay B after applying the threshold function okay so there almost no differences [Music] between [Music] that d f now exp objects in an image [Music] strong puppy but also [Music] the nice okay now let's get to brief on what we need to study about rnm okay model that is to process and convert a

0:50:44 -  sequen into sequential data input into a specific sequential data output is sentence time based on the complex semantics and okay start Quest let's see for for o for [Music] for [Music] this for all all for what for all for this for [Music] for all [Music] sh for what for C for for for for for for for for we understand so we'll continue more on RNN tomorrow we have explored CNN more today which we not expecting we starting off with RNN but CNN we had some few right questions to ask because we just thought okay image comes and then we we classify the image and then call it whether it's a dog or a cat as simple but the the mod to as we do in the image image classification or is is more object detection but the key question that that came in is like how do uh people do object detection using CNS but the answer is CNN doesn't do um see object detection and object labeling there are two concepts labeling is good be done by CNN but but object detection is not being done by CNN object detection is being done by other tools like open City and that that doesn't actually I mean technically point is that doesn't need AI or network based tools we can actually do it using normal open CV based uh mean algorithm based applications which can actually detect the edges within this images which actually gives multi levels also what is